

-Huge footer.  Links to courses, social media for me, etc.  Any link I can think of.
-It's okay to have a box of text with only a shadow, no border (or nav bar)
-Black text not black.  Coursera had about a #252525
-Main page felt flowy and almost mobile design because it was all centered
	with a good degree of margin on the sides (10%-15% each side)
-Pack things a bit tight so it feels full and competent
-Some nav links on the top left, then log in button and sign in button to the right
-Less obvious and sharp borders and markers are better (shadows, clean color lines with no border, etc)



Experience notes:
-I want the user to be automatically redirected to the login page at times, but for it to automatically take them to their
	original desired destination when it is done processing their new/existing account.
-No blank account page for when not logged in.  redirect.
-Progress page either different or non-existent if not logged in.  Redirect or see promo about progress possibilities.



Pages:
-index
-contact
-topics
	-page for each topic's lessons (each lesson page has side bar nav for points in that lesson) (side nav with colored banner top)
-account pages
	-sign in
	-sign up
	-log out
	-see account
-my progress
	-chosen topics to learn, progress in each



Things for the index page
-nav (sign-in/up, topics page button that also drops down, contact/suggestions, account if signed in, my progress)
-Title
-Subtext describing site
-"Lessons at every level"
-Button for topics page ||OR|| sign up button if not signed in
-Background for why this page
-Image of me?  OR of something else
-Progress tracking page promo, link to it
-Final logo again and link to go to topics page
-Footer with all kinds of links.  Link to each Lesson/Topic?



------------------------------[ HTML and PHP layout end here ]--------------------------------------
-------------------------[ Topics and Content make up rest of file ]--------------------------------
Thoughts on Items:
I don't think we need a section on error functions. They might not make sense until the model itself is learned,
and if there was a section, they would basically need to be cut up into sections based on what kind of models they
were usable in anyways.  Maybe a cheat-sheet later.

Topics:
Each topic has points, each of which are lessons.  A lesson has multiple pages of content that is
made up of text explanations, videos, images, quizzes, and possibly some interactive stuff too.
So, it is: Topic -> Lessons -> Pages
And pages might and might not be utilized. MAybe later for the more complicated topics





Background Mathematics
-Machine Learning overview (what it is and isn't)
-Derivatives / basic calculus (Short of gradient descent)
-matrices and their operations


General Learning Things
-Gradient Descent - what is it and how is it done? (Vanilla)
-Hyperparameters and how to use / tune them
-	<Then do model topics?>
-Evaluating a model (accuracy || loss/error || generalization)
-Evaluation continued (conf matrix || roc curve)
-Comparing models (compare stats || roc curve comparison)


Linear Regression
-General goal of model && terms defined
-Hyperparameters and Learned values
-Gradient Descent - How it looks and the Math behind it (least square error, then descent)
-Problems and Sticking points


Logistic Regression
-General goal of model && terms defined
-Hyperparameters and Learned values
-Gradient Descent - How it looks and the Math behind it (Binary cross entropy loss)
-Problems and Sticking points


Multiple / Multinomial Linear and Logistic Regression
-Expanding our previous models - how
-Matrices at work (multiple gradients || different operations and input)
-Implications of high dimensionality in our learned values
-Visualizing Multivariate Descent (Hopefully find a way to show the implications of multivariate descent on a single axis dimension (bouncing around))


Different methods of Gradient Descent
-Vanilla and it's pitfalls (teaser for visualizing loss functions in high dimensionality)
-Stochastic - What is different about it and it's pros and cons
-Adagrad - what it does and how that helps
-Momentum - what it does and how it helps
-rmsProp - How it is different from Adagrad and why that is a good thing
-Adam - How it puts all these together and why it works well


Decision Trees
-What it is, how it is structured, and how it classifies
-Training (or growing) a tree
-pros and cons to decision trees (tease for ensembles and forests)


Vanilla Neural Networks
-Feed Forward - intro, intuition and math
-Back Prop - intuition and math
-Mathematical background on how it works (more like Killian's, with his example of lines and funcs)
-Derivatives in a Neural Network (visual explanation, then a mathematical one.  Think of that kid's medium post)
-Hyperparameters of a Neural Network (layers || nodes per each layer || batch_size || epoch_count)





Future content:
support vector machines
ensembles  (random forest || bagging)
visualizing high-dimensional loss functions
skip connections in neural nets
CNNs (how convolutions work and it's derivatives)
RNNs (Why feeding previous result back in is powerful) (Vanilla)
LSTMs (how they work and how they help)



					
					
					
Next bits for Graident Descent:
-Mathmatical definition of gradient, weight, and change.  Then add in learn rate
-(LR is tease for Hyperparameters (next time lesson) ).
-Gradient of weight = derivative of error with respect to weight
-